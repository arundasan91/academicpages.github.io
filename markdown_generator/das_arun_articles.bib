@article{Kwasniewska2019,
abstract = {This paper focuses on convolution neural network quantization problem. The quantization has a distinct stage of data conversion from floating-point into integer-point numbers. In general, the process of quantization is associated with the reduction of the matrix dimension via limited precision of the numbers. However, the training and inference stages of deep learning neural network are limited by the space of the memory and a variety of factors including programming complexity and even reliability of the system. On the whole the process of quantization becomes more and more popular due to significant impact on performance and minimal accuracy loss. Various techniques for networks quantization have been already proposed, including quantization aware training and integer arithmetic-only inference. Yet, a detailed comparison of various quantization configurations, combining all proposed methods haven't been presented yet. This comparison is important to understand selection of quantization hyperparameters during training to optimize networks for inference while preserving their robustness. In this work, we perform in-depth analysis of parameters in the quantization aware training, the process of simulating precision loss in the forward pass by quantizing and dequantizing tensors. Specifically, we modify rounding modes, input preprocessing, output data signedness, bitwidth of the quantization and locations of precision loss simulation to evaluate how they affect accuracy of deep neural network aimed at performing efficient calculations on resource-constrained devices.},
author = {Kwasniewska, Alicja and Szankin, Maciej and Ozga, Mateusz and Wolfe, Jason and Das, Arun and Zajac, Adam and Ruminski, Jacek and Rad, Paul},
doi = {10.1109/IECON.2019.8927153},
isbn = {9781728148786},
journal = {IECON Proc. (Industrial Electron. Conf.},
keywords = {Deep neural network,artificial intelligence,data analysis,edge devices,quantization,quantization aware training},
month = {oct},
pages = {96--101},
publisher = {IEEE},
title = {{Deep Learning Optimization for Edge Devices: Analysis of Training Quantization Parameters}},
url = {https://ieeexplore.ieee.org/document/8927153/},
volume = {2019-October},
year = {2019}
}
@article{Torres2018,
abstract = {This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion. The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time. Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.},
author = {Torres, Alex D. and Yan, Hao and Aboutalebi, Armin Haj and Das, Arun and Duan, Lide and Rad, Paul},
doi = {10.1016/B978-0-12-813314-9.00003-7},
isbn = {9780128133149},
journal = {Comput. Intell. Multimed. Big Data Cloud with Eng. Appl.},
keywords = {Adaboost,Cloud computing,Convolutional neural network,Decoupled computer architecture,Deep learning,Face detection,Facial emotion recognition,Machine learning,Multi-tenant system},
pages = {61--89},
publisher = {Elsevier},
title = {{Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration}},
url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128133149000037},
year = {2018}
}
@article{Das2018,
author = {Das, Arun and Lin, Wei-Ming and Rad, Paul},
doi = {10.1201/9781351119023-7},
journal = {Appl. Cloud Deep Semant. Recognit.},
month = {apr},
pages = {131--159},
publisher = {Auerbach Publications},
title = {{A Distributed Secure Machine-Learning Cloud Architecture for Semantic Analysis}},
url = {https://www.taylorfrancis.com/books/9781351119016/chapters/10.1201/9781351119023-7},
year = {2018}
}
@article{Das2019,
abstract = {The ability to perform screening of potential vision-impairing diseases remotely with an Ophthalmologist-in-the-loop is crucial in serving the Medically Underserved Areas/Population (MUA/P) and in acute medical settings, such as emergency departments. With an estimated 217 million individuals affected by moderate to severe vision-impairing diseases worldwide and an increasing number of new patients with such diseases, the need for access to faster (or real-time) diagnosis on a large scale is imperative. It is evident that early diagnosis of chronic diseases such as diabetic retinopathy and age-related macular degeneration (AMD) could better prevent vision loss. In this paper, a scalable cloud based teleophthalmology architecture via the Internet of Medical Things (IoMT) for diagnosis of AMD is presented. In the proposed architecture, patients wear a head-mounted camera (OphthoAI IoMT headset) to send their retinal fundus images to their secure and private cloud drive storage for personalized disease severity detection and predictive progression analysis. A proposed AMD-ResNet convolution neural network with 152 layers will then analyze the images to identify and determine AMD disease severity. The algorithm is trained with AREDS (age related eye disease study) images from the National Institute of Health (NIH) with over 130,000 fundus images captured over 12 years, and for determining AMD severity, we achieve a sensitivity and specificity of 94.97 ± 0.5{\%} and 98.32 ± 0.1{\%} respectively. A temporal Long–Short Term Memory (LSTM) deep neural network for precision medicine and AMD predictive progression is also proposed. Patient personalization allows better targeted care, lesser side effects, and a greater likelihood of responding to treatments by tailoring healthcare on a per-patient basis.},
author = {Das, Arun and Rad, Paul and Choo, Kim Kwang Raymond and Nouhi, Babak and Lish, Jonathan and Martel, James},
doi = {10.1016/j.future.2018.10.050},
issn = {0167739X},
journal = {Futur. Gener. Comput. Syst.},
keywords = {Deep learning,Internet of Medical Things (IoMT),Macular degeneration,Mobile-cloud teleophthalmology,Telemedicine,Teleophthalmology,Wearable IoMT},
pages = {486--498},
title = {{Distributed machine learning cloud teleophthalmology IoT for predicting AMD disease progression}},
volume = {93},
year = {2019}
}
@article{Das2020,
abstract = {Nowadays, deep neural networks are widely used in mission critical systems such as healthcare, self-driving vehicles, and military which have direct impact on human lives. However, the black-box nature of deep neural networks challenges its use in mission critical applications, raising ethical and judicial concerns inducing lack of trust. Explainable Artificial Intelligence (XAI) is a field of Artificial Intelligence (AI) that promotes a set of tools, techniques, and algorithms that can generate high-quality interpretable, intuitive, human-understandable explanations of AI decisions. In addition to providing a holistic view of the current XAI landscape in deep learning, this paper provides mathematical summaries of seminal work. We start by proposing a taxonomy and categorizing the XAI techniques based on their scope of explanations, methodology behind the algorithms, and explanation level or usage which helps build trustworthy, interpretable, and self-explanatory deep learning models. We then describe the main principles used in XAI research and present the historical timeline for landmark studies in XAI from 2007 to 2020. After explaining each category of algorithms and approaches in detail, we then evaluate the explanation maps generated by eight XAI algorithms on image data, discuss the limitations of this approach, and provide potential future directions to improve XAI evaluation.},
journal = {arXiv Preprint},
archivePrefix = {arXiv},
arxivId = {2006.11371},
author = {Das, Arun and Rad, Paul},
eprint = {2006.11371},
month = {jun},
title = {{Opportunities and Challenges in Explainable Artificial Intelligence (XAI): A Survey}},
url = {http://arxiv.org/abs/2006.11371},
year = {2020}
}