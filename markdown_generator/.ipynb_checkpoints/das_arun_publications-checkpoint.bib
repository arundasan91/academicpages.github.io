@inproceedings{Panwar2017,
abstract = {Deep feature learning methods have been aggressively applied in the field of music tagging retrieval Genre categorization, mood classification, and chord detection are the most common tags from local spectral to temporal structure. Convolutional Neural networks (CNNs) using kernels extract the local features that are in different levels of hierarchy while Recurrent Neural Networks (RNNs) discover the global features to understand the temporal context, CRNN architectures as a powerful music tagging utilize the benefits of the both CNN and RNN structures. In this article a CRNN structure on MagnaTagA Tune dataset is proposed. The AUC-ROC index for the proposed architecture is 0.893 which shows its superiority rather than traditional structures on the same database. The merging mechanism to obtain 50 tags from the whole 188 existing tags of this dataset and simple CRNN architecture designed for tag discovering are the main contribution of this paper.},
author = {Panwar, Sharaj and Das, Arun and Roopaei, Mehdi and Rad, Paul},
booktitle = {2017 12th Syst. Syst. Eng. Conf. SoSE 2017},
doi = {10.1109/SYSOSE.2017.7994970},
isbn = {9781509059454},
keywords = {Cloud Computing,Deep Learning,Magna Tag A Tune,Music Decomposition,Music Genre Recognition,Music Tagging,Recurrent Neural Network,Tag Retrieval},
title = {{A deep learning approach for mapping music genres}},
year = {2017}
}
@inproceedings{Sahba2018,
abstract = {Image captioning is the process of analyzing an image and generating a textual description according to objects and actions in the image. Thus, both image processing and natural language understanding are required for an image captioning system. Applications of image captioning can vary from assisting visually impaired people to detecting fake news in social media. One of significant utilizations of image captioning would be the detection of particular actions in images. In this paper, we use image captioning to produce a textual description from an image. Then we exploit a natural language processing algorithm to extract main components in the produced description. Finally we generate a general graph according to detected components in descriptions of the image. The generated graph shows objects and pairwise relationship between them along with their attributes. Thus, it can be used to determine if there is any particular relation in a sequence of input images.},
author = {Sahba, Amin and Das, Arun and Rad, Paul and Jamshidi, Mo},
booktitle = {World Autom. Congr. Proc.},
doi = {10.23919/WAC.2018.8430485},
isbn = {9781532377914},
issn = {21544832},
month = {jun},
pages = {193--198},
publisher = {IEEE},
title = {{Image Graph Production by Dense Captioning}},
url = {https://ieeexplore.ieee.org/document/8430485/},
volume = {2018-June},
year = {2018}
}